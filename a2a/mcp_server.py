"""MCP Server for CSTP Decision Intelligence.

Exposes CSTP capabilities as MCP tools so any MCP-compliant agent
(Claude Desktop, OpenClaw, etc.) can discover and use decision
intelligence natively.

Transports:
    - stdio: ``python -m a2a.mcp_server`` (local / Docker exec)
    - Streamable HTTP: mounted at ``/mcp`` on the FastAPI server (remote)

The ``mcp_app`` Server instance is importable for mounting into other
ASGI applications (see ``a2a/server.py``).
"""

import asyncio
import contextvars
import json
import logging
import sys
from typing import Any

from mcp.server import Server
from mcp.server.stdio import stdio_server
from mcp.types import (
    TextContent,
    Tool,
)

from .mcp_schemas import (
    CheckActionInput,
    GetDecisionInput,
    GetGraphInput,
    GetNeighborsInput,
    GetReasonStatsInput,
    GetSessionContextInput,
    GetStatsInput,
    LinkDecisionsInput,
    LogDecisionInput,
    PreActionInput,
    QueryDecisionsInput,
    ReadyInput,
    RecordThoughtInput,
    ReviewOutcomeInput,
    UpdateDecisionInput,
)


def _deref_schema(schema: dict[str, Any]) -> dict[str, Any]:
    """Dereference $ref/$defs in a JSON Schema for LLM API compatibility.

    Many LLM APIs (OpenAI, Anthropic, etc.) don't support $ref references
    in tool schemas. This function inlines all $ref references and removes
    the $defs block, producing a flat schema.
    """
    defs = schema.get("$defs", {})
    if not defs:
        return schema

    # Work on a copy to avoid mutating the input
    result = {k: v for k, v in schema.items() if k != "$defs"}

    def _resolve(node: Any, seen: frozenset[str] = frozenset()) -> Any:
        if isinstance(node, dict):
            if "$ref" in node:
                ref_path = node["$ref"]  # e.g., "#/$defs/ReasonInput"
                ref_name = ref_path.rsplit("/", 1)[-1]
                if ref_name in seen:
                    # Circular reference - return empty object to break loop
                    return {"type": "object"}
                if ref_name in defs:
                    return _resolve(dict(defs[ref_name]), seen | {ref_name})
                return node
            return {k: _resolve(v, seen) for k, v in node.items()}
        if isinstance(node, list):
            return [_resolve(item, seen) for item in node]
        return node

    return _resolve(result)

# Configure logging to stderr (stdout is reserved for MCP protocol)
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    stream=sys.stderr,
)
logger = logging.getLogger("cstp-mcp")

# F023 Phase 2: ContextVar for MCP session tracking key
# Set by the HTTP handler or defaults to "mcp:default"
_mcp_tracker_key: contextvars.ContextVar[str] = contextvars.ContextVar(
    "_mcp_tracker_key", default="mcp:default"
)


def get_mcp_tracker_key() -> str:
    """Get the current MCP tracker key for deliberation tracking."""
    return _mcp_tracker_key.get()


# Server instance — importable for mounting in ASGI apps (see a2a/server.py)
mcp_app = Server("cstp-decisions")


def _build_query_params(args: QueryDecisionsInput) -> dict[str, Any]:
    """Convert Pydantic input to CSTP query params dict."""
    params: dict[str, Any] = {
        "query": args.query,
        "limit": args.limit,
        "retrievalMode": args.retrieval_mode,
    }
    if args.filters:
        filters: dict[str, Any] = {}
        if args.filters.category:
            filters["category"] = args.filters.category
        if args.filters.stakes:
            filters["stakes"] = args.filters.stakes
        if args.filters.status:
            filters["status"] = args.filters.status
        if args.filters.project:
            filters["project"] = args.filters.project
        if args.filters.feature:
            filters["feature"] = args.filters.feature
        if args.filters.pr is not None:
            filters["pr"] = args.filters.pr
        if args.filters.min_confidence is not None:
            filters["minConfidence"] = args.filters.min_confidence
        if args.filters.max_confidence is not None:
            filters["maxConfidence"] = args.filters.max_confidence
        if args.filters.has_outcome is not None:
            filters["hasOutcome"] = args.filters.has_outcome
        if filters:
            params["filters"] = filters
    # F024: Pass bridge_side
    if args.bridge_side:
        params["bridgeSide"] = args.bridge_side
    return params


def _build_guardrails_params(args: CheckActionInput) -> dict[str, Any]:
    """Convert Pydantic input to CSTP guardrails params dict."""
    action: dict[str, Any] = {
        "description": args.description,
        "stakes": args.stakes,
    }
    if args.category:
        action["category"] = args.category
    if args.confidence is not None:
        action["confidence"] = args.confidence
    return {"action": action}


@mcp_app.list_tools()
async def list_tools() -> list[Tool]:
    """List available CSTP tools for MCP discovery."""
    return [
        Tool(
            name="query_decisions",
            description=(
                "Low-level: Search similar past decisions using semantic search, keyword "
                "matching, or hybrid retrieval. Returns matching decisions with confidence "
                "scores, categories, and outcomes. Prefer pre_action for decision-making "
                "workflows (combines query + guardrails + record in one call). Use this "
                "directly only for exploratory search without recording."
            ),
            inputSchema=_deref_schema(QueryDecisionsInput.model_json_schema()),
        ),
        Tool(
            name="check_action",
            description=(
                "Low-level: Validate an intended action against safety guardrails and "
                "policies. Returns whether the action is allowed, any violations "
                "(blocking), and warnings. Prefer pre_action which includes guardrail "
                "checks automatically. Use this directly only for standalone what-if "
                "guardrail checks without querying or recording."
            ),
            inputSchema=_deref_schema(CheckActionInput.model_json_schema()),
        ),
        Tool(
            name="log_decision",
            description=(
                "Low-level: Record a decision to the immutable decision log. Include "
                "what you decided, your confidence level, category, and supporting "
                "reasons. Prefer pre_action with auto_record=true which queries + "
                "checks guardrails + records in one call. Use this directly only for "
                "after-the-fact recording when pre_action was not used."
            ),
            inputSchema=_deref_schema(LogDecisionInput.model_json_schema()),
        ),
        Tool(
            name="review_outcome",
            description=(
                "Record the outcome of a past decision. Provide the decision ID, "
                "whether it succeeded or failed, what actually happened, and lessons "
                "learned. Builds calibration data over time."
            ),
            inputSchema=_deref_schema(ReviewOutcomeInput.model_json_schema()),
        ),
        Tool(
            name="get_stats",
            description=(
                "Low-level: Get calibration statistics: Brier score, accuracy, "
                "confidence distribution, and decision counts. Optionally filter by "
                "category, project, or time window. Prefer get_session_context which "
                "includes calibration alongside decisions, guardrails, and patterns. "
                "Use this directly for monitoring dashboards or CI checks."
            ),
            inputSchema=_deref_schema(GetStatsInput.model_json_schema()),
        ),
        Tool(
            name="get_decision",
            description=(
                "Retrieve full details of a single decision by ID. Returns the "
                "complete record including context, reasons, project metadata, "
                "outcome, and review information. Use when you need the full "
                "decision content beyond what query_decisions returns."
            ),
            inputSchema=_deref_schema(GetDecisionInput.model_json_schema()),
        ),
        Tool(
            name="get_reason_stats",
            description=(
                "Analyze which reason types (analysis, pattern, empirical, etc.) "
                "correlate with better decision outcomes. Shows per-type success "
                "rates, Brier scores, and diversity analysis (do decisions with "
                "more diverse reasoning perform better?). Use to improve "
                "decision-making by understanding which reasoning approaches work."
            ),
            inputSchema=_deref_schema(GetReasonStatsInput.model_json_schema()),
        ),
        Tool(
            name="update_decision",
            description=(
                "Update specific fields on an existing decision. Currently "
                "supports updating tags and pattern. Use for backfilling "
                "decisions with missing metadata."
            ),
            inputSchema=_deref_schema(UpdateDecisionInput.model_json_schema()),
        ),
        Tool(
            name="record_thought",
            description=(
                "Record a reasoning/chain-of-thought step in the deliberation "
                "trace. In pre-decision mode (no decision_id), thoughts "
                "accumulate and auto-attach to the next recorded decision. "
                "In post-decision mode (with decision_id), appends to the "
                "existing decision's deliberation trace."
            ),
            inputSchema=_deref_schema(RecordThoughtInput.model_json_schema()),
        ),
        # F046: Pre-action hook
        Tool(
            name="pre_action",
            description=(
                "PRIMARY - Call this BEFORE any significant decision. All-in-one: "
                "queries similar past decisions, evaluates guardrails, fetches "
                "calibration context, extracts confirmed patterns, and optionally "
                "records the decision. One round-trip replaces separate calls to "
                "query_decisions + check_action + log_decision."
            ),
            inputSchema=_deref_schema(PreActionInput.model_json_schema()),
        ),
        # F047: Session context
        Tool(
            name="get_session_context",
            description=(
                "PRIMARY - Call at session start or when switching tasks. Returns "
                "full cognitive context: agent profile (accuracy, Brier score, "
                "tendency), relevant past decisions, active guardrails, calibration "
                "by category, overdue reviews, and confirmed patterns. Available in "
                "JSON or markdown format for direct system prompt injection."
            ),
            inputSchema=_deref_schema(GetSessionContextInput.model_json_schema()),
        ),
        # F044: Agent Work Discovery
        Tool(
            name="ready",
            description=(
                "PRIMARY - Returns prioritized cognitive actions needing attention: "
                "outcome reviews (overdue decisions), calibration drift (per-category "
                "degradation), and stale pending decisions. Call during idle periods "
                "or after completing tasks to discover maintenance work. Filter by "
                "priority (low/medium/high), action types, or category."
            ),
            inputSchema=_deref_schema(ReadyInput.model_json_schema()),
        ),
        # F045: Graph tools
        Tool(
            name="link_decisions",
            description=(
                "Create a typed relationship edge between two decisions. "
                "Edge types: relates_to (topical similarity), supersedes "
                "(newer replaces older), depends_on (prerequisite). "
                "Builds the decision knowledge graph over time."
            ),
            inputSchema=_deref_schema(LinkDecisionsInput.model_json_schema()),
        ),
        Tool(
            name="get_graph",
            description=(
                "Get a subgraph of related decisions around a center node. "
                "Traverses the decision knowledge graph up to a specified "
                "depth. Returns nodes with metadata and edges with types. "
                "Use for understanding decision clusters and dependencies."
            ),
            inputSchema=_deref_schema(GetGraphInput.model_json_schema()),
        ),
        Tool(
            name="get_neighbors",
            description=(
                "Get immediate neighbors of a decision in the knowledge "
                "graph. Lighter-weight than get_graph -- returns a flat "
                "list of directly connected decisions with their "
                "relationship edges. Use for quick context lookup."
            ),
            inputSchema=_deref_schema(GetNeighborsInput.model_json_schema()),
        ),
    ]


@mcp_app.call_tool()
async def call_tool(name: str, arguments: dict[str, Any]) -> list[TextContent]:
    """Dispatch tool calls to CSTP services."""
    logger.info("Tool called: %s", name)

    try:
        if name == "query_decisions":
            return await _handle_query_decisions(arguments)

        if name == "check_action":
            return await _handle_check_action(arguments)

        if name == "log_decision":
            return await _handle_log_decision(arguments)

        if name == "review_outcome":
            return await _handle_review_outcome(arguments)

        if name == "get_stats":
            return await _handle_get_stats(arguments)

        if name == "get_decision":
            return await _handle_get_decision_mcp(arguments)

        if name == "get_reason_stats":
            return await _handle_get_reason_stats_mcp(arguments)

        if name == "update_decision":
            return await _handle_update_decision_mcp(arguments)

        if name == "record_thought":
            return await _handle_record_thought_mcp(arguments)

        if name == "pre_action":
            return await _handle_pre_action_mcp(arguments)

        if name == "get_session_context":
            return await _handle_get_session_context_mcp(arguments)

        if name == "ready":
            return await _handle_ready_mcp(arguments)

        if name == "link_decisions":
            return await _handle_link_decisions_mcp(arguments)

        if name == "get_graph":
            return await _handle_get_graph_mcp(arguments)

        if name == "get_neighbors":
            return await _handle_get_neighbors_mcp(arguments)

        raise ValueError(f"Unknown tool: {name}")

    except ValueError as e:
        logger.warning("Validation error in tool %s: %s", name, e)
        return [
            TextContent(
                type="text",
                text=json.dumps({"error": "validation_error", "message": str(e)}),
            )
        ]
    except Exception as e:
        # Catches pydantic.ValidationError and any other unexpected errors
        error_type = "validation_error" if "ValidationError" in type(e).__name__ else "internal_error"
        logger.error("Tool %s failed (%s): %s", name, type(e).__name__, e, exc_info=True)
        return [
            TextContent(
                type="text",
                text=json.dumps({"error": error_type, "message": str(e)}),
            )
        ]


async def _handle_query_decisions(arguments: dict[str, Any]) -> list[TextContent]:
    """Handle query_decisions tool call."""
    import time

    from .cstp.models import (
        DecisionSummary,
        QueryDecisionsRequest,
        QueryDecisionsResponse,
    )
    from .cstp.query_service import query_decisions

    start_time = time.time()

    # Validate input via Pydantic
    args = QueryDecisionsInput(**arguments)

    # Convert to CSTP request
    params = _build_query_params(args)
    request = QueryDecisionsRequest.from_params(params)

    # Execute query - use effective_query for bridge-side prefix (F024)
    response = await query_decisions(
        query=request.effective_query,
        n_results=request.limit,
        category=request.filters.category,
        min_confidence=(
            request.filters.min_confidence
            if request.filters.min_confidence > 0
            else None
        ),
        max_confidence=(
            request.filters.max_confidence
            if request.filters.max_confidence < 1
            else None
        ),
        stakes=request.filters.stakes,
        status_filter=request.filters.status,
        project=request.filters.project,
        feature=request.filters.feature,
        pr=request.filters.pr,
        has_outcome=request.filters.has_outcome,
    )

    # P2: Surface query errors instead of masking them
    if response.error:
        raise RuntimeError(response.error)

    query_time_ms = int((time.time() - start_time) * 1000)

    # Convert QueryResponse results to DecisionSummary list
    decisions = []
    for r in response.results:
        decisions.append(
            DecisionSummary(
                id=r.id[:8] if len(r.id) > 8 else r.id,
                title=r.title[:50],
                category=r.category or "",
                confidence=r.confidence,
                stakes=r.stakes,
                status=r.status or "",
                outcome=r.outcome,
                date=r.date or "",
                distance=r.distance,
                reasons=None,
                tags=r.tags,
                pattern=r.pattern,
            )
        )

    # Build proper response with to_dict()
    result_obj = QueryDecisionsResponse(
        decisions=decisions,
        total=len(decisions),
        query=request.query,
        query_time_ms=query_time_ms,
        agent="mcp-client",
        retrieval_mode=request.retrieval_mode,
        scores={},
    )
    result = result_obj.to_dict()

    # F023 Phase 2: Track query for auto-deliberation
    from .cstp.deliberation_tracker import track_query

    track_query(
        key=get_mcp_tracker_key(),
        query=request.query,
        result_count=result_obj.total,
        top_ids=[d.id for d in result_obj.decisions[:5]],
        retrieval_mode=request.retrieval_mode,
    )

    return [
        TextContent(
            type="text",
            text=json.dumps(result, indent=2, default=str),
        )
    ]


async def _handle_check_action(arguments: dict[str, Any]) -> list[TextContent]:
    """Handle check_action tool call."""
    from .cstp.guardrails_service import evaluate_guardrails, log_guardrail_check
    from .cstp.models import CheckGuardrailsRequest

    # Validate input via Pydantic
    args = CheckActionInput(**arguments)

    # Convert to CSTP request
    params = _build_guardrails_params(args)
    request = CheckGuardrailsRequest.from_params(params)

    # Build evaluation context (matches dispatcher pattern)
    context: dict[str, Any] = {
        "category": request.action.category,
        "stakes": request.action.stakes,
        "confidence": request.action.confidence,
    }
    if request.action.context:
        # Merge additional context but don't overwrite explicit params
        for k, v in request.action.context.items():
            if k not in context:
                context[k] = v

    # Evaluate guardrails
    eval_result = await evaluate_guardrails(context)

    # Log the check
    log_guardrail_check(
        requesting_agent="mcp-client",
        action_description=request.action.description,
        allowed=eval_result.allowed,
        violations=eval_result.violations,
        evaluated=eval_result.evaluated,
    )

    # Map to response format
    violations = [
        {
            "guardrail_id": v.guardrail_id,
            "name": v.name,
            "message": v.message,
            "severity": v.severity,
        }
        for v in eval_result.violations
    ]

    warnings = [
        {
            "guardrail_id": w.guardrail_id,
            "name": w.name,
            "message": w.message,
            "severity": w.severity,
        }
        for w in eval_result.warnings
    ]

    result = {
        "allowed": eval_result.allowed,
        "violations": violations,
        "warnings": warnings,
        "evaluated": eval_result.evaluated,
    }

    # F023 Phase 2: Track guardrail check for auto-deliberation
    from .cstp.deliberation_tracker import track_guardrail

    track_guardrail(
        key=get_mcp_tracker_key(),
        description=request.action.description,
        allowed=eval_result.allowed,
        violation_count=len(eval_result.violations),
    )

    return [
        TextContent(
            type="text",
            text=json.dumps(result, indent=2, default=str),
        )
    ]


async def _handle_log_decision(arguments: dict[str, Any]) -> list[TextContent]:
    """Handle log_decision tool call."""
    from .cstp.decision_service import RecordDecisionRequest, record_decision

    # Validate input via Pydantic
    args = LogDecisionInput(**arguments)

    # Build params dict for CSTP
    params: dict[str, Any] = {
        "decision": args.decision,
        "confidence": args.confidence,
        "category": args.category,
        "stakes": args.stakes,
    }
    if args.context:
        params["context"] = args.context
    if args.reasons:
        params["reasons"] = [{"type": r.type, "text": r.text} for r in args.reasons]
    if args.tags:
        params["tags"] = args.tags
    if args.project:
        params["project"] = args.project
    if args.feature:
        params["feature"] = args.feature
    if args.pr is not None:
        params["pr"] = args.pr

    # F023: Pass deliberation trace
    if args.deliberation:
        delib: dict[str, Any] = {}
        if args.deliberation.inputs:
            delib["inputs"] = [
                {"id": i.id, "text": i.text, **({"source": i.source} if i.source else {})}
                for i in args.deliberation.inputs
            ]
        if args.deliberation.steps:
            delib["steps"] = [
                {
                    "step": s.step,
                    "thought": s.thought,
                    **({"inputs_used": s.inputs_used} if s.inputs_used else {}),
                    **({"type": s.type} if s.type else {}),
                    **({"conclusion": s.conclusion} if s.conclusion else {}),
                }
                for s in args.deliberation.steps
            ]
        if args.deliberation.total_duration_ms is not None:
            delib["total_duration_ms"] = args.deliberation.total_duration_ms
        if delib:
            params["deliberation"] = delib

    # F024: Pass bridge-definition
    if args.bridge:
        bridge_data: dict[str, Any] = {
            "structure": args.bridge.structure,
            "function": args.bridge.function,
        }
        if args.bridge.tolerance:
            bridge_data["tolerance"] = args.bridge.tolerance
        if args.bridge.enforcement:
            bridge_data["enforcement"] = args.bridge.enforcement
        if args.bridge.prevention:
            bridge_data["prevention"] = args.bridge.prevention
        params["bridge"] = bridge_data

    # Create request and record
    request = RecordDecisionRequest.from_dict(params, agent_id=args.agent_id or "mcp-client")

    # Build composite tracker key for multi-agent isolation
    from .cstp.deliberation_tracker import build_tracker_key

    tracker_key = build_tracker_key(
        agent_id=args.agent_id,
        decision_id=args.decision_id,
        transport_key="mcp-session",
    )

    # F025: Extract related decisions BEFORE consuming tracker
    from .cstp.deliberation_tracker import extract_related_from_tracker

    if not request.related_to:
        related_raw = extract_related_from_tracker(tracker_key)
        if related_raw:
            from .cstp.decision_service import RelatedDecision

            request.related_to = [
                RelatedDecision.from_dict(r) for r in related_raw
            ]

    # F023 Phase 2: Auto-attach deliberation from tracked inputs
    from .cstp.deliberation_tracker import auto_attach_deliberation

    request.deliberation, auto_captured = auto_attach_deliberation(
        key=tracker_key,
        deliberation=request.deliberation,
    )

    # F027 P2: Smart bridge extraction
    from .cstp.bridge_hook import maybe_smart_extract_bridge

    bridge_auto, bridge_method = await maybe_smart_extract_bridge(request)

    response = await record_decision(request)

    # F045 follow-up: Auto-link decision in graph
    auto_linked = 0
    if response.success and response.id:
        from .cstp.graph_service import safe_auto_link

        related_dicts = [r.to_dict() for r in request.related_to] if request.related_to else []
        auto_linked = await safe_auto_link(
            response_id=response.id,
            category=request.category,
            stakes=request.stakes,
            confidence=request.confidence,
            tags=list(request.tags),
            pattern=request.pattern,
            related_to=related_dicts,
        )

    # Format response
    result = response.to_dict()
    if auto_captured and request.deliberation:
        result["deliberation_auto"] = True
        result["deliberation_inputs_count"] = len(request.deliberation.inputs)

    # F026: Run guardrails against record context
    from .cstp.guardrails_service import evaluate_record_guardrails
    record_warnings = await evaluate_record_guardrails(request)
    if record_warnings:
        result["guardrail_warnings"] = record_warnings

    if bridge_auto and request.bridge:
        result["bridge_auto"] = True
        result["bridge_method"] = bridge_method

    if request.related_to:
        result["related_count"] = len(request.related_to)

    if auto_linked > 0:
        result["graph_edges_created"] = auto_linked

    return [
        TextContent(
            type="text",
            text=json.dumps(result, indent=2, default=str),
        )
    ]


async def _handle_review_outcome(arguments: dict[str, Any]) -> list[TextContent]:
    """Handle review_outcome tool call."""
    from .cstp.decision_service import ReviewDecisionRequest, review_decision

    # Validate input via Pydantic
    args = ReviewOutcomeInput(**arguments)

    # Build params dict for CSTP
    params: dict[str, Any] = {
        "id": args.id,
        "outcome": args.outcome,
    }
    if args.actual_result:
        params["actualResult"] = args.actual_result
    if args.lessons:
        params["lessons"] = args.lessons
    if args.notes:
        params["notes"] = args.notes

    # Create request and review
    request = ReviewDecisionRequest.from_dict(params, reviewer_id="mcp-client")
    response = await review_decision(request)

    # Format response
    result = response.to_dict()
    return [
        TextContent(
            type="text",
            text=json.dumps(result, indent=2, default=str),
        )
    ]


async def _handle_get_stats(arguments: dict[str, Any]) -> list[TextContent]:
    """Handle get_stats tool call."""
    from .cstp.calibration_service import GetCalibrationRequest, get_calibration

    # Validate input via Pydantic
    args = GetStatsInput(**arguments)

    # Build request directly
    request = GetCalibrationRequest(
        category=args.category,
        project=args.project,
        window=args.window,
    )

    # Get calibration stats
    response = await get_calibration(request)

    # Format response
    result = response.to_dict()
    return [
        TextContent(
            type="text",
            text=json.dumps(result, indent=2, default=str),
        )
    ]


async def _handle_get_decision_mcp(arguments: dict[str, Any]) -> list[TextContent]:
    """Handle get_decision tool call."""
    from .cstp.decision_service import GetDecisionRequest, get_decision

    # Validate input via Pydantic
    args = GetDecisionInput(**arguments)

    # Create request and fetch
    request = GetDecisionRequest.from_dict({"id": args.id})
    response = await get_decision(request)

    # F023 Phase 2: Track lookup for auto-deliberation
    if response.found:
        from .cstp.deliberation_tracker import track_lookup

        dec = response.decision or {}
        track_lookup(
            key=get_mcp_tracker_key(),
            decision_id=args.id,
            title=dec.get("summary", dec.get("decision", ""))[:50],
        )

    # Format response
    result = response.to_dict()
    return [
        TextContent(
            type="text",
            text=json.dumps(result, indent=2, default=str),
        )
    ]


async def _handle_get_reason_stats_mcp(arguments: dict[str, Any]) -> list[TextContent]:
    """Handle get_reason_stats tool call."""
    from .cstp.reason_stats_service import GetReasonStatsRequest, get_reason_stats

    # Validate input via Pydantic
    args = GetReasonStatsInput(**arguments)

    # Build params dict for CSTP
    params: dict[str, Any] = {
        "minReviewed": args.min_reviewed,
    }
    if args.filters:
        filters: dict[str, Any] = {}
        if args.filters.category:
            filters["category"] = args.filters.category
        if args.filters.stakes:
            filters["stakes"] = args.filters.stakes
        if args.filters.project:
            filters["project"] = args.filters.project
        if filters:
            params["filters"] = filters

    # Create request and fetch
    request = GetReasonStatsRequest.from_dict(params)
    response = await get_reason_stats(request)

    # Format response
    result = response.to_dict()

    # F023 Phase 2: Track stats lookup for auto-deliberation
    from .cstp.deliberation_tracker import track_stats

    track_stats(
        key=get_mcp_tracker_key(),
        total_decisions=result.get("totalDecisions", 0),
        reason_type_count=len(result.get("byReasonType", [])),
        diversity=result.get("diversity", {}).get("avgTypesPerDecision"),
    )

    return [
        TextContent(
            type="text",
            text=json.dumps(result, indent=2, default=str),
        )
    ]


async def _handle_update_decision_mcp(arguments: dict[str, Any]) -> list[TextContent]:
    """Handle update_decision tool call."""
    from .cstp.decision_service import update_decision

    input_data = UpdateDecisionInput(**arguments)

    updates: dict[str, Any] = {}
    if input_data.decision is not None:
        updates["decision"] = input_data.decision
    if input_data.confidence is not None:
        updates["confidence"] = input_data.confidence
    if input_data.context is not None:
        updates["context"] = input_data.context
    if input_data.tags is not None:
        updates["tags"] = input_data.tags
    if input_data.pattern is not None:
        updates["pattern"] = input_data.pattern

    if not updates:
        return [TextContent(type="text", text=json.dumps({"error": "No fields to update"}))]

    result = await update_decision(input_data.id, updates)

    return [TextContent(type="text", text=json.dumps(result))]


async def _handle_record_thought_mcp(arguments: dict[str, Any]) -> list[TextContent]:
    """Handle record_thought tool call (F028)."""
    from .cstp.deliberation_tracker import track_reasoning

    input_data = RecordThoughtInput(**arguments)

    if input_data.decision_id:
        # Try post-decision append first (decision already exists)
        from .cstp.decision_service import append_thought, find_decision

        found = await find_decision(input_data.decision_id)
        if found:
            result = await append_thought(input_data.decision_id, input_data.text)
            if not result.get("success"):
                return [TextContent(type="text", text=json.dumps({"error": result.get("error", "Unknown error")}))]
            return [TextContent(type="text", text=json.dumps({
                "success": True,
                "mode": "post-decision",
                "decision_id": input_data.decision_id,
                "step_number": result["step_number"],
            }))]
        # Decision not found — fall through to pre-decision tracker
        # with decision_id scoping (decision will be recorded later)

    # Pre-decision: accumulate in tracker with composite key
    from .cstp.deliberation_tracker import build_tracker_key

    tracker_key = build_tracker_key(
        agent_id=input_data.agent_id,
        decision_id=input_data.decision_id,
        transport_key="mcp-session",
    )
    track_reasoning(tracker_key, input_data.text)
    return [TextContent(type="text", text=json.dumps({
        "success": True,
        "mode": "pre-decision",
        "tracker_key": tracker_key,
    }))]


async def _handle_pre_action_mcp(arguments: dict[str, Any]) -> list[TextContent]:
    """Handle pre_action tool call (F046)."""
    from .cstp.models import PreActionRequest
    from .cstp.preaction_service import pre_action

    # Validate input via Pydantic
    args = PreActionInput(**arguments)

    # Build params dict for CSTP
    params: dict[str, Any] = {
        "action": {
            "description": args.action.description,
            "stakes": args.action.stakes,
        },
    }
    if args.action.category:
        params["action"]["category"] = args.action.category
    if args.action.confidence is not None:
        params["action"]["confidence"] = args.action.confidence
    if args.options:
        params["options"] = {
            "queryLimit": args.options.query_limit,
            "autoRecord": args.options.auto_record,
        }
    if args.reasons:
        params["reasons"] = [
            {"type": r.type, "text": r.text} for r in args.reasons
        ]
    if args.tags:
        params["tags"] = args.tags
    if args.pattern:
        params["pattern"] = args.pattern

    request = PreActionRequest.from_params(params)
    response = await pre_action(request, agent_id="mcp-client")

    return [
        TextContent(
            type="text",
            text=json.dumps(response.to_dict(), indent=2, default=str),
        )
    ]


async def _handle_get_session_context_mcp(
    arguments: dict[str, Any],
) -> list[TextContent]:
    """Handle get_session_context tool call (F047)."""
    from .cstp.models import SessionContextRequest
    from .cstp.session_context_service import get_session_context

    # Validate input via Pydantic
    args = GetSessionContextInput(**arguments)

    # Build params dict for CSTP
    params: dict[str, Any] = {
        "decisionsLimit": args.decisions_limit,
        "readyLimit": args.ready_limit,
        "format": args.format,
    }
    if args.task_description:
        params["taskDescription"] = args.task_description
    if args.include:
        params["include"] = args.include

    request = SessionContextRequest.from_params(params)
    response = await get_session_context(request, agent_id="mcp-client")

    return [
        TextContent(
            type="text",
            text=json.dumps(response.to_dict(), indent=2, default=str),
        )
    ]


async def _handle_ready_mcp(arguments: dict[str, Any]) -> list[TextContent]:
    """Handle ready tool call (F044)."""
    from .cstp.models import ReadyRequest
    from .cstp.ready_service import get_ready_actions

    args = ReadyInput(**arguments)

    params: dict[str, Any] = {
        "minPriority": args.min_priority,
        "limit": args.limit,
    }
    if args.action_types:
        params["actionTypes"] = args.action_types
    if args.category:
        params["category"] = args.category

    request = ReadyRequest.from_params(params)
    response = await get_ready_actions(request)

    return [
        TextContent(
            type="text",
            text=json.dumps(response.to_dict(), indent=2, default=str),
        )
    ]


async def _handle_link_decisions_mcp(arguments: dict[str, Any]) -> list[TextContent]:
    """Handle link_decisions tool call (F045)."""
    from .cstp.graph_service import link_decisions

    args = LinkDecisionsInput(**arguments)

    response = await link_decisions(
        source_id=args.source_id,
        target_id=args.target_id,
        edge_type=args.edge_type,
        weight=args.weight,
        context=args.context,
        agent_id="mcp-client",
    )
    return [
        TextContent(
            type="text",
            text=json.dumps(response.to_dict(), indent=2, default=str),
        )
    ]


async def _handle_get_graph_mcp(arguments: dict[str, Any]) -> list[TextContent]:
    """Handle get_graph tool call (F045)."""
    from .cstp.graph_service import get_graph

    args = GetGraphInput(**arguments)

    response = await get_graph(
        node_id=args.node_id,
        depth=args.depth,
        edge_types=list(args.edge_types) if args.edge_types else None,
        direction=args.direction,
    )
    return [
        TextContent(
            type="text",
            text=json.dumps(response.to_dict(), indent=2, default=str),
        )
    ]


async def _handle_get_neighbors_mcp(arguments: dict[str, Any]) -> list[TextContent]:
    """Handle get_neighbors tool call (F045)."""
    from .cstp.graph_service import get_neighbors

    args = GetNeighborsInput(**arguments)

    response = await get_neighbors(
        node_id=args.node_id,
        direction=args.direction,
        edge_type=args.edge_type,
        limit=args.limit,
    )
    return [
        TextContent(
            type="text",
            text=json.dumps(response.to_dict(), indent=2, default=str),
        )
    ]


async def run_stdio() -> None:
    """Run the MCP server with stdio transport."""
    logger.info("Starting CSTP MCP server (stdio transport)")

    async with stdio_server() as (read_stream, write_stream):
        await mcp_app.run(
            read_stream,
            write_stream,
            mcp_app.create_initialization_options(),
        )


def main() -> None:
    """Entry point for the MCP server."""
    asyncio.run(run_stdio())


if __name__ == "__main__":
    main()
