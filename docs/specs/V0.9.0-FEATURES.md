# CSTP v0.9.0 Features - Calibration Improvements

## Overview

v0.9.0 focuses on improving calibration intelligence based on community feedback from Moltbook discussion.

---

## F014: Rolling Calibration Windows

**Priority:** High
**Complexity:** Medium

### Problem
Current calibration is all-time only. Recent performance may differ from historical. An agent improving over time looks the same as one getting worse.

### Solution
Add time-windowed calibration metrics:
- 30-day rolling window
- 60-day rolling window  
- 90-day rolling window
- Per-category breakdown for each window

### API Changes
```python
# cstp.getCalibration params
{
    "window": "30d" | "60d" | "90d" | "all",  # new param
    "category": "architecture",  # existing
    "project": "owner/repo"  # existing
}

# Response additions
{
    "overall": {
        "window": "30d",
        "period_start": "2026-01-06T00:00:00Z",
        "period_end": "2026-02-05T00:00:00Z",
        ...existing fields...
    }
}
```

### Implementation
1. Add `window` param to `getCalibration`
2. Filter decisions by `created_at` timestamp
3. Add period metadata to response

---

## F015: Calibration Drift Alerts

**Priority:** High  
**Complexity:** Medium

### Problem
Agents don't know when their calibration is degrading. By the time they check, damage is done.

### Solution
Proactive drift detection:
- Compare recent window (30d) to historical (90d+)
- Alert when Brier score degrades >20%
- Alert when accuracy drops >15%
- New API method: `cstp.checkDrift`

### API
```python
# cstp.checkDrift
{
    "threshold_brier": 0.20,  # 20% degradation trigger
    "threshold_accuracy": 0.15,  # 15% drop trigger
    "category": null  # optional filter
}

# Response
{
    "drift_detected": true,
    "alerts": [
        {
            "type": "brier_degradation",
            "category": "architecture",
            "recent_value": 0.15,
            "historical_value": 0.08,
            "change_pct": 87.5,
            "message": "Architecture decisions: Brier score degraded 87% (0.08 → 0.15)"
        }
    ],
    "recommendations": [...]
}
```

### Implementation
1. Add `checkDrift` method
2. Compare 30d vs 90d+ metrics
3. Generate alerts with actionable messages

---

## F016: Confidence Variance Tracking

**Priority:** Medium
**Complexity:** Low

### Problem
Agents may habituate to a "safe" confidence (always 85%). This defeats calibration - if you never vary, you can't learn.

### Solution
Track confidence distribution:
- Mean confidence
- Standard deviation
- Min/max range
- Entropy of confidence buckets
- Alert when variance too low

### API
```python
# Added to cstp.getCalibration response
{
    "confidence_stats": {
        "mean": 0.82,
        "std_dev": 0.08,
        "min": 0.60,
        "max": 0.95,
        "entropy": 2.1,  # higher = more varied
        "bucket_counts": {
            "0.5-0.6": 5,
            "0.6-0.7": 12,
            "0.7-0.8": 25,
            "0.8-0.9": 45,
            "0.9-1.0": 13
        }
    },
    "recommendations": [
        {
            "type": "low_variance",
            "message": "90% of decisions use 80-90% confidence. Consider varying more."
        }
    ]
}
```

### Implementation
1. Calculate stats in `getCalibration`
2. Add to response
3. Generate variance recommendations

---

## F017: Hybrid Retrieval Scoring

**Priority:** Medium
**Complexity:** Medium

### Problem
Pure semantic search misses exact keyword matches. Searching "CSRF" might not find decisions with "CSRF" if embedding focuses on "security".

### Solution
Combine semantic + BM25 keyword scoring:
- Semantic score (ChromaDB)
- BM25 keyword score
- Weighted combination (configurable)

### API
```python
# cstp.queryDecisions params
{
    "query": "CSRF protection",
    "retrieval_mode": "semantic" | "keyword" | "hybrid",  # new
    "hybrid_weight": 0.7,  # semantic weight (keyword = 1 - this)
    ...
}
```

### Implementation
1. Add BM25 index alongside ChromaDB
2. Query both on hybrid mode
3. Merge and re-rank results
4. Return combined scores

---

## Implementation Order

| Order | Feature | Effort | Value |
|-------|---------|--------|-------|
| 1 | F014: Rolling Windows | 2h | High - immediate insight |
| 2 | F016: Confidence Variance | 1h | Medium - quick win |
| 3 | F015: Drift Alerts | 2h | High - proactive |
| 4 | F017: Hybrid Retrieval | 3h | Medium - better search |

**Total estimated:** ~8 hours

---

## Decision

**Recommended approach:** Sequential, starting with F014.

Rolling windows (F014) provides the foundation for drift detection (F015). Confidence variance (F016) is independent and quick. Hybrid retrieval (F017) is isolated and can be done last.

```
F014 (rolling) → F015 (drift) → F016 (variance) → F017 (hybrid)
     ↓                ↑
     └────depends on──┘
```
